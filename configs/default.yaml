parameters:
    main:
        env: 'tmaze'
        name: 'environments:tmaze-v0'
        algorithm: 'PPO'
        num_workers: 1
        n_stack: 30
        eval_episodes: 100
        eval_deterministic: false
        eval_freq: 1.0e+4
        total_steps: 1.0e+5
        epsilon: 0.1
        beta: 1.0e-2
        c1: 1.0
        learning_rate: 1.0e-3
        gae_lambda: 0.95
        learning_rate_final: 1.0e-3
        hidden_size: 128
        hidden_size_2: 128
        batch_size: 32
        rollout_steps: 128
        num_epoch: 3
        random_action_prob: 0.0
        gamma: 0.99
        normalize_advantage: false
        use_advantage: true
        